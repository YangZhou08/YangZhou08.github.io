<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="icon" href="images/namename.png" type="image/png">
    <title>Yang Zhou</title>

    <meta name="author" content="Yang Zhou">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="icon" href="images/namename.png" type="image/png">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">

    <style>
        body {
            font-family: Arial, sans-serif;
        }
        /* Scrollable container */
        .news-container {
            max-height: 200px;  /* Set a height limit for the container */
            overflow-y: auto;   /* Enables vertical scrolling when content exceeds max height */
            padding: 10px;
            border: 1px solid #ccc;
        }
        .news-item {
            margin-bottom: 20px;
        }
        .news-item h3 {
            color: #808080;
        }
        .news-item p {
            margin: 5px 0;
        }
    </style>
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Yang Zhou (周旸) 
                </p>
                <p>Yang Zhou here. I am a PhD student at <a href="https://www.cmu.edu/">Carnegie Mellon University</a>, fortunately working with <a href="https://www.andrew.cmu.edu/user/beidic/">Prof. Beidi Chen</a>. Previously, I was fortunate to work with <a href="https://users.ece.utexas.edu/~dianam/"> Prof. Diana Marculescu</a> on EdgeAI and with <a href="https://people.eecs.berkeley.edu/~keutzer/">Prof. Kurt Keutzer</a> on model quantization. I obtained my bachelor degree at <a href="https://www.utexas.edu/">The University of Texas at Austin</a>, studying Electrical and Computer Engineering. </a>
                </p>
                <p>
                  My current research focus lies in understanding and improving Large Language Models' reasoning and planning ability with special attention for inference scaling efficiency. I am eager to explore and welcome meaningful collaborations of any kind. If you are aligned with my research ideas and would like to discuss, please don't hesitate to reach out. 
                </p>
                <p style="text-align:center">
                  <a href="malito:yangzho6@andrew.cmu.edu">Email</a> &nbsp;/&nbsp;
                  <a href="data/YangZhou-CV.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?view_op=list_works&hl=en&hl=en&user=W6CZltIAAAAJ">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://x.com/IronSteveZhou">X/Twitter</a> &nbsp;/&nbsp;
                  <a href="https://github.com/YangZhou08">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/webtemphead1.png"><img style="width:100%;max-width:100%;object-fit: cover;" alt="profile photo" src="images/webtemphead1.png" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>

          <!-- Scrollable News Section -->
          <div class="news-container"> 
            <img src="images/newicons.png" alt="news" width="30"> 
            <!-- <span>Latest News</span> -->
            <h2>Latest News</h2> 

            <div class="news-item">
              <h3>September 2024</h3>
              <p><strong>One paper (Sirius)</strong> get accepted at NeurIPS</p>
            </div>

            <div class="news-item">
                <h3>February 2024</h3>
                <p><strong>One survey paper (LLM Unveiled)</strong> is now on ArXiv</p>
            </div>

            <div class="news-item">
                <h3>August 2023</h3>
                <p><strong>Started Graduate school at CMU</strong></p>
            </div>

            <div class="news-item">
                <h3>May 2023</h3>
                <p><strong>Graduated from UT Austin</strong></p>
            </div>
          </div>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  Most of them related to model compression with the focus of efficiency. Some are <span style="background-color: #ffffd0;">Highlighted</span>. (Updated in Oct. 2024) 
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

    <tr style="background-color: #ffffd0;">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div style="display: flex; align-items: center; height: 100%;">
          <img src='images/siriushead.png' width="300" alt="Sirius Image">
        </div> 
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://infini-ai-lab.github.io/Sirius/">
			<span class="papertitle">Sirius: Contextual Sparsity with Correction for Efficient LLM</span>
        </a>
        <br>
				<strong>Yang Zhou</strong>,
        <a href="https://dreaming-panda.github.io/">Zhuoming Chen</a>, 
        <a href="https://ottovonxu.github.io/">Zhaozhuo Xu</a>,
        <a href="https://victorialin.net/">Victoria Lin</a>, 
				<a href="https://www.andrew.cmu.edu/user/beidic/">Beidi Chen</a>

        <br>
        <em>NeurIPS</em>, 2024 &nbsp 
        <br>
        <a href="https://infini-ai-lab.github.io/Sirius/">project page</a>
        /
        <a href="https://www.arxiv.org/abs/2409.03856">arXiv</a>
        /
        <a href="https://github.com/YangZhou08/deep-gradient-compression">code</a>
        <p>
				We reveal that contextual sparsity struggles at complex reasoning tasks. We propose a efficient correction method to recover the accuracy degradation of contextual sparsity models while maintaining their efficiency. 
        </p>
    </tr>

    <tr style="background-color: #ffffd0;">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div style="display: flex; align-items: center; height: 100%;">
          <img src='images/llmunveiled.png' width="300" alt="Sirius Image">
        </div> 
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://arxiv.org/abs/2402.16363">
			<span class="papertitle">LLM Inference Unveiled: Survey and Roofline Model Insights</span>
        <!--  Zhihang Yuan, Yuzhang Shang, Yang Zhou, Zhen Dong, Zhe Zhou, Chenhao Xue, Bingzhe Wu, Zhikai Li, Qingyi Gu, Yong Jae Lee, Yan Yan, Beidi Chen, Guangyu Sun, Kurt Keutzer ---> 
        </a>
        <br>
				<a href="https://zhihang.cc/">Zhihang Yuan</a>*,
        <a href="https://42shawn.github.io/">Yuzhang Shang</a>*, 
        <strong>Yang Zhou*</strong>
        <a href="https://dong-zhen.com/">Zhen Dong</a>, 
				<a href="">Zhe Zhou</a>, 
        <a href="">Chenhao Xue</a>, 
        <a href="">Bingzhe Wu</a>, 
        <a href="https://dong-zhen.com/">Zhikai Li</a>, 
        <a href="https://dong-zhen.com/">Qingyi Gu</a>, 
        <a href="https://yongjaelee.com/">Yong Jae Lee</a>, 
        <a href="https://tomyan555.github.io/">Yan Yan</a>, 
        <a href="https://www.andrew.cmu.edu/user/beidic/">Beidi Chen</a>, 
        <a href="https://ceca.pku.edu.cn/en/people_/faculty_/guangyu_sun/">Guangyu Sun</a>,
        <a href="https://www.eecs.berkeley.edu/~kurt/">Kurt Keutzer</a>

        <br>
        <em>Manuscript</em>, 2024 &nbsp 
        <br>
        <a href="https://github.com/hahnyuan/LLM-Viewer">LLM-Viewer</a>
        /
        <a href="https://arxiv.org/abs/2402.16363">arXiv</a>
        <p>
				We breakdown the LLM inference memory bottlenecks and present algorithm/hardware/system considerations in improving the serving/inference of LLMs. Besides presenting a comprehensive summary of previous works in LLM inference optimation from algorithm, system, and hardware perspectives, we also introduce a roofline modeling tool called LLM-Viewer. LLM-Viewer helps LLM practitioners to visualize their workflow taylored to their specific LLM model and hardware setup. 
        </p>
    </tr> 

    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div style="display: flex; align-items: center; height: 100%;">
          <img src='images/hexgen.png' width="300" alt="HexGen Image">
        </div> 
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://arxiv.org/abs/2311.11514v2">
          <span class="papertitle">HexGen: Generative Inference of Large-Scale Foundation Model over Heterogeneous Decentralized Environment</span>
        </a>
        <br>
        <a href="">Youhe Jiang</a>, 
        <a href="">Ran Yan</a>, 
        <a href="">Xiaozhe Yao</a>, 
        <strong>Yang Zhou</strong>, 
        <a href="">Beidi Chen</a>, 
        <a href="">Binhang Yuan</a>
        <br>
        <em>ICML 2024</em>, 2023 &nbsp 
        <br>
        <a href="https://arxiv.org/abs/2311.11514v2">arXiv link</a> 
        <p>
          This paper focuses on deploying such services in a heterogeneous and decentralized setting to mitigate the substantial inference costs typically associated with centralized data centers. Towards this end, we propose HexGen, a flexible distributed inference engine that uniquely supports the asymmetric partition of generative inference computations over both tensor model parallelism and pipeline parallelism and allows for effective deployment across diverse GPUs interconnected by a fully heterogeneous network.
        </p>
      </td>
    </tr>

    <tr style="background-color: #ffffd0;">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div style="display: flex; align-items: center; height: 100%;">
          <img src='images/dqrm.png' width="300" alt="Sirius Image">
        </div> 
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://github.com/YangZhou08/Deep_Quantized_Recommendation_Model_DQRM">
			<span class="papertitle">DQRM: Deep Quantized Recommendation Model</span>
        </a>
        <br>
        <!--- Yang Zhou, Zhen Dong, Ellick Chan, Dhiraj Kalamkar, Diana Marculescu, Kurt Keutzer ---> 
				<strong>Yang Zhou</strong>,
        <a href="https://dong-zhen.com/">Zhen Dong</a>, 
        <a href="https://ellickchan.github.io/">Ellick Chan</a>, 
        <a href="https://dhirajkalamkar.github.io/">Dhiraj Kalamkar</a>, 
        <a href="https://www.ece.utexas.edu/people/faculty/diana-marculescu">Diana Marculescu</a>,
        <a href="https://www.eecs.berkeley.edu/~kurt/">Kurt Keutzer</a> 

        <br>
        <em>Manuscript</em>, 2023 &nbsp 
        <br>
        <a href="https://github.com/YangZhou08/Deep_Quantized_Recommendation_Model_DQRM">arXiv</a> 
        / 
        <a href="https://github.com/YangZhou08/Deep_Quantized_Recommendation_Model_DQRM">Code</a> 
        <p>
				We propose a variant of DLRM that is efficient to be trained and do inference using quantization. We first show that INT4 QAT is able to give on-par/exceeds performance of FP32 DLRM. We then build a system that train the 4-bit quantized model with 1% sparse gradient. 
        </p>
    </tr> 

    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div style="display: flex; align-items: center; height: 100%;">
          <img src='images/play_it_cool.png' width="300" alt="Sirius Image">
        </div> 
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://arxiv.org/abs/2206.10849">
			<span class="papertitle">Play It Cool: Dynamic Shifting Prevents Thermal Throttling</span>
        </a>
        <br>
				<strong>Yang Zhou</strong>,
        <a href="https://jeff-liangf.github.io">Jeff Liang</a>, 
        <a href="https://rudychin.github.io/">Ting-wu Chin</a>,
        <a href="https://www.ece.utexas.edu/people/faculty/diana-marculescu">Diana Marculescu</a>

        <br>
        <em>DyNN @ ICML (Oral)</em>, 2022 &nbsp 
        <br>
        <a href="https://arxiv.org/abs/2206.10849">arXiv</a> 
        <p>
				We notice that deploying powerful neural networks on the edge devices tends to lead to thermal emergency which force OS to throttle the frequency of CPU. We propose a dynamic shifting method to prevent thermal throttling by shifting between the weak and strong models of the same dynamic network. 
        </p>
    </tr> 

    <tr style="background-color: #ffffd0;">
      <td style="padding:20px;width:25%;vertical-align:center">
        <div style="display: flex; align-items: center; height: 100%;">
          <img src='images/ant.png' width="300" alt="ANT Image">
        </div> 
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://openaccess.thecvf.com/content/CVPR2022W/ECV/papers/Liang_ANT_Adapt_Network_Across_Time_for_Efficient_Video_Processing_CVPRW_2022_paper.pdf">
          <span class="papertitle">ANT: Adapt Network Across Time for Efficient Video Processing</span>
        </a>
        <br>
        <a href="https://jeff-liangf.github.io">Feng Liang</a>, 
        <a href="https://rudychin.github.io/">Ting-Wu Chin</a>, 
        <strong>Yang Zhou</strong>, 
        <a href="https://www.ece.utexas.edu/people/faculty/diana-marculescu">Diana Marculescu</a>
        <br>
        <em>CVPRW ECV</em>, 2022 &nbsp 
        <br>
        <a href="https://openaccess.thecvf.com/content/CVPR2022W/ECV/papers/Liang_ANT_Adapt_Network_Across_Time_for_Efficient_Video_Processing_CVPRW_2022_paper.pdf">arXiv</a> 
        <p>
          we propose the ANT framework to harness these redundancies for reducing the computational cost of video processing. The proposed ANT adapts a purpose-fit network by inspecting the semantic differences between frames.
        </p>
      </td>
    </tr>

    </tbody></table>
      
    <h2>Selected Honors</h2>
    <ul>
      <li><strong>Carnegie Institute of Technology Dean's Fellowship</strong>, Awarded 2023-2024</li>
      <li><strong>College Scholar</strong> 2023, <strong>Top 10%</strong>, University of Texas at Austin</li>
      <li><strong>Distinguished College Scholar</strong>, 2022 <strong>Top 4%</strong>, University of Texas at Austin</li> 
      <li><strong>Distinguished College Scholar</strong>, 2021 <strong>Top 4%</strong>, University of Texas at Austin</li> 
      <li><strong>Engineering Honor Student</strong>, <strong>Top 10%</strong>, Oct. 2020 to May 2023</li> 
    </ul>

    <h2>Services</h2>
    Reviewer of ECCV 2023, MLsys 2024 
            
            
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Last updated: October 2024. Webpage thanks to <a href="https://jonbarron.info/">Jon Barron</a>. 
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
